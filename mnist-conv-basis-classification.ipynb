{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ffa709",
   "metadata": {
    "id": "29ffa709"
   },
   "source": [
    "# Train CNN on MNIST\n",
    "\n",
    "We need to train to do regression on the one-hot MNIST labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72004e9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72004e9a",
    "outputId": "96e86ebe-4416-4f39-d7d6-614bee5a9b65"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ---- Load MNIST data ----\n",
    "mnist_digits = MNIST(root=\"./data\", train=True, download=True).data\n",
    "mnist_labels = MNIST(root=\"./data\", train=True, download=True).targets\n",
    "test_digits = MNIST(root=\"./data\", train=False, download=True).data\n",
    "test_labels = MNIST(root=\"./data\", train=False, download=True).targets\n",
    "\n",
    "# ---- Convert to PyTorch tensors ----\n",
    "X = mnist_digits.float().reshape(-1, 1, 28, 28) / 255.0\n",
    "y = mnist_labels.long()\n",
    "\n",
    "## Randomly shuffle\n",
    "indices = torch.randperm(X.shape[0])\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(\n",
    "    X,\n",
    "    torch.nn.functional.one_hot(y, num_classes=10),\n",
    ")\n",
    "test_ds = TensorDataset(X, y)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256)\n",
    "\n",
    "# ---- Initialize model, loss, optimizer ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class TrainingInfo:\n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "        self.epochs = 0\n",
    "        self.train_losses = []\n",
    "        self.test_accuracies = {}  # epoch -> accuracy\n",
    "        self.leverage_scores = {}  # epoch -> leverage scores array\n",
    "\n",
    "    def to_json(self):\n",
    "        leverage_scores_serialized = {}\n",
    "        for k, arr in self.leverage_scores.items():\n",
    "            torch.save(arr, buf := io.BytesIO())\n",
    "            leverage_scores_serialized[str(k)] = base64.b85encode(buf.getvalue()).decode('ascii')\n",
    "        return {\n",
    "            \"epochs\": self.epochs,\n",
    "            \"train_losses\": self.train_losses,\n",
    "            \"test_accuracies\": self.test_accuracies,\n",
    "            \"leverage_scores\": leverage_scores_serialized\n",
    "        }\n",
    "\n",
    "    def from_json(self, data: dict):\n",
    "        self.epochs = data[\"epochs\"]\n",
    "        self.train_losses = data[\"train_losses\"]\n",
    "        self.test_accuracies = data[\"test_accuracies\"]\n",
    "        leverage_scores_deserialized = {}\n",
    "        for k, b85str in data[\"leverage_scores\"].items():\n",
    "            byte_data = base64.b85decode(b85str.encode('ascii'))\n",
    "            buf = io.BytesIO(byte_data)\n",
    "            leverage_scores_deserialized[int(k)] = torch.load(buf, weights_only=False)\n",
    "        self.leverage_scores = leverage_scores_deserialized\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.json_path, \"w\") as f:\n",
    "            json.dump(self.to_json(), f)\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        self.from_json(data)\n",
    "\n",
    "    def __enter__(self):\n",
    "        if Path(self.json_path).exists():\n",
    "            self.load()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ---- Define CNN model ----\n",
    "from models.mnist_cnn import MnistConvNet\n",
    "\n",
    "combined_digits = torch.cat([mnist_digits, test_digits], dim=0).to(device).float().reshape(-1, 1, 28, 28) / 255.0\n",
    "\n",
    "# Create a DataLoader for combined_digits to process in batches\n",
    "combined_dataset = TensorDataset(combined_digits)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=256, shuffle=False) # Use a reasonable batch size\n",
    "\n",
    "def leverage_scores(model: MnistConvNet, data_loader: DataLoader): # Changed data to data_loader\n",
    "    \"\"\"Compute leverage scores for the model's embedding of the data in batches.\"\"\"\n",
    "    all_embeddings = []\n",
    "    for batch in data_loader:\n",
    "        xb = batch[0].to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings_batch = model.embed(xb).cpu()\n",
    "        all_embeddings.append(embeddings_batch)\n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    Q, _ = torch.linalg.qr(full_embeddings)\n",
    "    leverage = torch.sum(Q**2, dim=1)\n",
    "    return leverage\n",
    "\n",
    "\n",
    "for i in [10, 20, 50, 100, 150, 200, 250, 300, 400, 500, 1000]:\n",
    "    model_path = Path(f\"models/mnist_cnn_R{i}_classify.pth\")\n",
    "    info_path = Path(f\"training_info/mnist_cnn_R{i}_classify_info.json\")\n",
    "    with TrainingInfo(info_path) as info:\n",
    "        if model_path.exists():\n",
    "            model = MnistConvNet(i).to(device)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            print(\"Loaded pre-trained model.\")\n",
    "        else:\n",
    "            print(\"No pre-trained model found. Initializing new model.\")\n",
    "            model = MnistConvNet(i).to(device)\n",
    "            print(\"Measuring initial leverage scores\")\n",
    "            # Measure initial leverage scores\n",
    "            model.eval()\n",
    "            # Pass the DataLoader instead of the raw tensor\n",
    "            info.leverage_scores[info.epochs] = leverage_scores(model, combined_loader).cpu().numpy()\n",
    "\n",
    "        print(f\"Training MnistConvNet with R={i}...\")\n",
    "        criterion = torch.nn.CrossEntropyLoss()  # Changed from SmoothL1Loss\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Increased learning rate\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "        # ---- Training loop ----\n",
    "        for epoch in range(2):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(xb)\n",
    "                loss = criterion(preds, yb.float()) # Ensure yb is float for SmoothL1Loss, though CrossEntropyLoss typically expects long for labels.\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f\"  Epoch {epoch+1}: train_loss = {total_loss / len(train_loader):.4f}\")\n",
    "            info.epochs += 1\n",
    "            info.train_losses.append(total_loss / len(train_loader))\n",
    "\n",
    "        # ---- Evaluation ----\n",
    "        model.eval()\n",
    "\n",
    "        # Measure leverage scores after training\n",
    "        with torch.no_grad():\n",
    "            # Pass the DataLoader instead of the raw tensor\n",
    "            info.leverage_scores[info.epochs] = leverage_scores(model, combined_loader).cpu().numpy()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                predicted = torch.argmax(preds, 1)\n",
    "                total += yb.size(0)\n",
    "                correct += (predicted == yb).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "        info.test_accuracies[info.epochs] = accuracy\n",
    "\n",
    "        # ---- Save model ----\n",
    "        torch.save(model.state_dict(), f\"models/mnist_cnn_R{i}_classify.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da686432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dimensions = [10,20,50,100,150,200,250,300,400,500,1000]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    3,\n",
    "    4,\n",
    "    figsize=(5 * 4, 5 * 3),\n",
    ")\n",
    "\n",
    "for i, dimension in enumerate(dimensions):\n",
    "    info_path = Path(f\"training_info/mnist_cnn_R{dimension}_classify_info.json\")\n",
    "    info = TrainingInfo(info_path)\n",
    "    info.load()\n",
    "    ax = axes[i // 4, i % 4]\n",
    "\n",
    "    for epoch, leverage_scores in info.leverage_scores.items():\n",
    "        y = np.sort(torch.tensor(leverage_scores).cpu().numpy())[::-1]\n",
    "        ax.scatter(np.arange(y.shape[0]), y, label=f\"Epoch {epoch}\", marker=\"x\")\n",
    "    ax.set_title(f\"Dimension {dimension}\")\n",
    "    ax.set_xlabel(\"Index\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"Leverage Score\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mnist_leverage_scores_by_dimension.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
