{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/jwcalder/GraphLearning/raw/master/Data/cifar10_labels.npz to /home/nathan/Desktop/AliasingOperatorExperiments/data/cifar10_labels.npz...\n",
      "Downloading http://www-users.math.umn.edu/~jwcalder/Data/cifar10_raw.npz to /home/nathan/Desktop/AliasingOperatorExperiments/data/cifar10_raw.npz...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "import graphlearning as gl\n",
    "\n",
    "mnist_digits, mnist_labels = gl.datasets.load(\"mnist\")\n",
    "cifar, cifar_labels = gl.datasets.load(\"cifar10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c0683",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Datasets:\n",
    "1. CIFAR-10\n",
    "2. MNIST\n",
    "\n",
    "Models:\n",
    "1. Convolutional Features\n",
    "2. ReLU Features\n",
    "3. Fourier Features\n",
    "\n",
    "Each model transforms the data to a feature matrix $[M_{TM} | M_{TU}]$ where $M_{TM}$ is the data matrix for the training set and $M_{TU}$ are the basis functions that we have not yet modeled. We will compute the best coefficients, $\\tilde{c}$ of basis functions to model the labels on the modeled training set and the best coefficients, $c$, of all basis functions to model the labels on the whole training set. We will then compute the error $c_{err} = \\tilde{c}-c^*$ where $c^*$ is the truncated version of $c$ to match the size of $\\tilde{c}$. We initialize $c$ with the least-squares coefficients learned from the whole training set. Then we compute $\\tilde{c}$ by solving the least-squares problem on the sampled training set. \n",
    "\n",
    "For each dataset, we will:\n",
    "- Sample the features uniformly at random vs by leverage scores.\n",
    "- Plot $||A||_2$, $||M_{TM}^+||_2$, and $||\\tilde{c}-c^*||_2$ for the sampled features as a function of the number of sampled points.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "The MNIST dataset consists of 70,000 images of handwritten digits (0-9) in grayscale with a resolution of 28x28 pixels. This gives us a $70,000 \\times 784$ data matrix.\n",
    "- A Convolutional Neural network will transform the data to a $70,000 \\times 200$ matrix (by removing the last layer).\n",
    "- A Random ReLU fully-connected network ($y({\\textbf{t}}) = \\sum_{k=1}^{200} w_k \\sigma(\\left<\\textbf{t}, {\\textbf{v}}_k\\right>)$ with $\\sigma(x) = \\max(0,x)$ and $\\textbf{v}_k$ being randomly initialized weights and $w_k$ being the learned coefficients) will transform the data to a $70,000 \\times 200$ matrix.\n",
    "- A Fourier fully-connected network ($y({\\textbf{t}}) = \\sum_{k=1}^{200} w_k \\exp(i\\pi\\left<\\textbf{t}, {\\textbf{v}}_k\\right>)$ with $\\textbf{v}_k$ being randomly initialized weights and $w_k$ being the learned coefficients) will transform the data to a $70,000 \\times 200$ matrix.\n",
    "\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 images in color with a resolution of 32x32 pixels, divided into 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). This gives us a 60,000 x 32 x 32 x 3 = 60,000 x 3072 data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
