{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17c0683",
   "metadata": {
    "id": "a17c0683"
   },
   "source": [
    "# Goal\n",
    "\n",
    "Datasets:\n",
    "1. CIFAR-10\n",
    "2. MNIST\n",
    "\n",
    "Models:\n",
    "1. Convolutional Features\n",
    "2. ReLU Features\n",
    "3. Fourier Features\n",
    "\n",
    "Each model transforms the data to a feature matrix $[M_{TM} | M_{TU}]$ where $M_{TM}$ is the data matrix for the training set and $M_{TU}$ are the basis functions that we have not yet modeled. We will compute the best coefficients, $\\tilde{c}$ of basis functions to model the labels on the modeled training set and the best coefficients, $c$, of all basis functions to model the labels on the whole training set. We will then compute the error $c_{err} = \\tilde{c}-c^*$ where $c^*$ is the truncated version of $c$ to match the size of $\\tilde{c}$. We initialize $c$ with the least-squares coefficients learned from the whole training set. Then we compute $\\tilde{c}$ by solving the least-squares problem on the sampled training set.\n",
    "\n",
    "For each dataset, we will:\n",
    "- Sample the features uniformly at random vs by leverage scores.\n",
    "- Plot $||A||_2$, $||M_{TM}^+||_2$, and $||\\tilde{c}-c^*||_2$ for the sampled features as a function of the number of sampled points.\n",
    "\n",
    "We expect to see that leverage score sampling leads to a smaller error $||\\tilde{c}-c^*||_2$ for the same number of sampled points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29ab21d",
   "metadata": {
    "id": "c29ab21d"
   },
   "source": [
    "\n",
    "## MNIST\n",
    "\n",
    "The MNIST dataset consists of 70,000 images of handwritten digits (0-9) in grayscale with a resolution of 28x28 pixels. This gives us a $70,000 \\times 784$ data matrix.\n",
    "- A Convolutional Neural network will transform the data to a $70,000 \\times 200$ matrix (by removing the last layer).\n",
    "- A Random ReLU fully-connected network ($y({\\textbf{t}}) = \\sum_{k=1}^{200} w_k \\sigma(\\left<\\textbf{t}, {\\textbf{v}}_k\\right>)$ with $\\sigma(x) = \\max(0,x)$ and $\\textbf{v}_k$ being randomly initialized weights and $w_k$ being the learned coefficients) will transform the data to a $70,000 \\times 200$ matrix.\n",
    "- A Fourier fully-connected network ($y({\\textbf{t}}) = \\mathscr{R}(\\sum_{k=1}^{200} w_k \\exp(i\\pi\\left<\\textbf{t}, {\\textbf{v}}_k\\right>)) = \\sum_{k=1}^{200} w_k \\cos(\\pi\\left<\\textbf{t}, {\\textbf{v}}_k\\right>) = $ with $\\textbf{v}_k$ being randomly initialized weights and $w_k$ being the learned coefficients) will transform the data to a $70,000 \\times 200$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55619",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0de55619",
    "outputId": "af635215-8a78-44c8-b8c2-19618545b3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using\", DEVICE)\n",
    "\n",
    "mnist_X = MNIST(root=\"./data\", train=True, download=True).data.float().to(DEVICE).reshape(-1, 1, 28, 28) / 255.0\n",
    "mnist_y = MNIST(root=\"./data\", train=True, download=True).targets.to(DEVICE)\n",
    "test_mnist_X =  MNIST(root=\"./data\", train=False, download=True).data.float().to(DEVICE).reshape(-1, 1, 28, 28) / 255.0\n",
    "test_mnist_y = MNIST(root=\"./data\", train=False, download=True).targets.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e49d7db0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e49d7db0",
    "outputId": "e5173c95-5617-4d3d-8cfa-5e9d75919ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "# Verify CNN accuracy on MNIST\n",
    "\n",
    "from models.mnist_cnn import MnistConvNet, BASIS_FUNCTIONS\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "network = MnistConvNet()\n",
    "network.load_state_dict(torch.load(\"models/mnist_cnn.pth\", map_location=DEVICE))\n",
    "network.eval()\n",
    "\n",
    "\n",
    "def verify_mnist_cnn(model: MnistConvNet, device):\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        TensorDataset(test_mnist_X, test_mnist_y),\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds: torch.Tensor = model(xb)\n",
    "            correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    print(f\"Test accuracy: {correct / total:.4f}\")\n",
    "\n",
    "\n",
    "verify_mnist_cnn(network, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea998e6",
   "metadata": {
    "id": "7ea998e6"
   },
   "source": [
    "We get an accuracy on the whole dataset of `0.9871` on the testing set. Pretty good. Now we can embed the data using the convolutional layers of the network and use that as our feature matrix for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d0781f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09d0781f",
    "outputId": "27c0bbf6-0d8c-46c1-e3c5-87722cc018eb"
   },
   "outputs": [],
   "source": [
    "# Random Fourier Features\n",
    "def rff_features(X, features=200) -> torch.Tensor:\n",
    "    N, *_ = X.shape\n",
    "    X = X.reshape(N, -1)\n",
    "\n",
    "    W = torch.randn(X.shape[1], features, device=X.device)\n",
    "\n",
    "    return torch.cos(torch.pi * X @ W) / np.sqrt(features)  # Normalize\n",
    "\n",
    "\n",
    "# Random ReLU Features\n",
    "def relu_features(X, features=200) -> torch.Tensor:\n",
    "    N, *_ = X.shape\n",
    "    X = X.reshape(N, -1)\n",
    "    W = torch.randn(X.shape[1], features, device=X.device)\n",
    "    return torch.relu(X @ W) / np.sqrt(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874f8441",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "874f8441",
    "outputId": "b19fca77-47a5-4356-f99b-7a2a52e161e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist cnn on cpu\n",
      "torch.Size([10000, 200])\n",
      "mnist rff on cpu\n",
      "torch.Size([10000, 200])\n",
      "mnist relu on cpu\n",
      "torch.Size([10000, 200])\n"
     ]
    }
   ],
   "source": [
    "# Embed the testing set (not the training set)\n",
    "def embed_dataset(X):\n",
    "    # Embed the data using the convolutional layers of the network\n",
    "    embeddings = torch.tensor(np.zeros((X.shape[0], BASIS_FUNCTIONS))).to(\n",
    "        DEVICE\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, X.shape[0], 256):\n",
    "            batch_end = min(batch_start + 256, X.shape[0])\n",
    "            batch = X[batch_start:batch_end].to(DEVICE)\n",
    "            batch_embeddings = network.embed(batch)\n",
    "            embeddings[batch_start:batch_end] = batch_embeddings\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "mnist_cnn_embedding = embed_dataset(test_mnist_X)\n",
    "print(\"mnist cnn on\", mnist_cnn_embedding.device)\n",
    "print(mnist_cnn_embedding.shape)\n",
    "\n",
    "mnist_rff_features = rff_features(test_mnist_X, features=200)\n",
    "print(\"mnist rff on\", mnist_rff_features.device)\n",
    "print(mnist_rff_features.shape)\n",
    "\n",
    "mnist_relu_features = relu_features(test_mnist_X, features=200)\n",
    "print(\"mnist relu on\", mnist_relu_features.device)\n",
    "print(mnist_relu_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d91274",
   "metadata": {
    "id": "99d91274"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch.linalg\n",
    "\n",
    "def parameter_error(\n",
    "    data: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    c_true: torch.Tensor,\n",
    "    indices: torch.Tensor,\n",
    "    lstsq_weights: torch.Tensor | None = None,\n",
    "    regularize: float = 1e-6,\n",
    "):\n",
    "    A = data[indices, :].double()\n",
    "    y = labels[indices, :].double()\n",
    "    if lstsq_weights is not None:\n",
    "        A *= torch.sqrt(lstsq_weights)[:, None]\n",
    "        y *= torch.sqrt(lstsq_weights)[:, None]\n",
    "    c_computed = torch.linalg.lstsq(\n",
    "        A.T @ A + regularize * torch.eye(data.shape[1], device=data.device),\n",
    "        A.T @ y,\n",
    "    ).solution\n",
    "    return (c_true.double() - c_computed).norm() / c_true.double().norm()\n",
    "\n",
    "\n",
    "def aliasing_op_norm(data: torch.Tensor, indices: torch.Tensor):\n",
    "    return torch.linalg.norm(\n",
    "        torch.linalg.pinv(data[indices, :]) @ data[indices, :], ord=\"fro\"\n",
    "    )\n",
    "\n",
    "\n",
    "def norm_M_pinv(data: torch.Tensor, indices: torch.Tensor):\n",
    "    return torch.linalg.norm(torch.linalg.pinv(data[indices, :]), ord=\"fro\")\n",
    "\n",
    "\n",
    "def simulation(\n",
    "    x_axis: list[int],\n",
    "    M: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    trials: int = 10,\n",
    "    regularize: float = 1e-6,\n",
    "):\n",
    "    device = M.device\n",
    "\n",
    "    if torch.linalg.matrix_rank(M) < M.shape[1]:\n",
    "        print(\n",
    "            f\"data is ill-conditioned {torch.linalg.matrix_rank(M)=} < {M.shape[1]=}, using regularization constant\",\n",
    "            regularize,\n",
    "        )\n",
    "        # Do Tikhonov/Ridge regularization\n",
    "        c_true = torch.linalg.lstsq(\n",
    "            M.T @ M\n",
    "            + regularize * torch.eye(M.shape[1], device=M.device),\n",
    "            M.T @ labels,\n",
    "        ).solution\n",
    "    else:\n",
    "        c_true = torch.linalg.lstsq(M, labels).solution\n",
    "\n",
    "    data = {\n",
    "        metric: {method: [] for method in [\"random\", \"leverage\", \"random_leverage\"]}\n",
    "        for metric in [\"parameter_error\", \"aliasing_error\", \"norm_M_pinv\"]\n",
    "    }\n",
    "\n",
    "    for n in x_axis:\n",
    "        print(f\"  Sampling {n} points...\")\n",
    "        total_p_err_random, total_err_random, total_M_pinv_random = (\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "        )\n",
    "        total_p_err_levg, total_err_levg, total_M_pinv_levg = (\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "        )\n",
    "        total_p_err_rand_levg, total_err_rand_levg, total_M_pinv_rand_levg = (\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "            torch.tensor(0.0, device=DEVICE),\n",
    "        )\n",
    "\n",
    "        for _ in range(trials):\n",
    "            leverage_scores = (\n",
    "                torch.linalg.norm(torch.linalg.qr(M, mode=\"reduced\").Q, dim=1) ** 2\n",
    "            )\n",
    "\n",
    "            random_indices = torch.randperm(M.shape[0], device=device)[:n]\n",
    "            random_weights = None  # Uniform weights for unweighted least squares\n",
    "            top_leverage_indices = torch.topk(leverage_scores, n, largest=True).indices\n",
    "            top_leverage_weights = leverage_scores[top_leverage_indices]\n",
    "            random_leverage_indices = torch.multinomial(\n",
    "                leverage_scores, n, replacement=True\n",
    "            )\n",
    "            random_leverage_weights = leverage_scores[random_leverage_indices]\n",
    "\n",
    "            for (indices, weights), (p_err_storage, aliasing_err_storage, M_pinv_norm_storage) in [\n",
    "                (\n",
    "                    (random_indices, random_weights),\n",
    "                    (total_p_err_random, total_err_random, total_M_pinv_random),\n",
    "                ),\n",
    "                (\n",
    "                    (top_leverage_indices, top_leverage_weights),\n",
    "                    (total_p_err_levg, total_err_levg, total_M_pinv_levg),\n",
    "                ),\n",
    "                (\n",
    "                    (random_leverage_indices, random_leverage_weights),\n",
    "                    (\n",
    "                        total_p_err_rand_levg,\n",
    "                        total_err_rand_levg,\n",
    "                        total_M_pinv_rand_levg,\n",
    "                    ),\n",
    "                ),\n",
    "            ]:\n",
    "                p_err_storage += parameter_error(\n",
    "                    M, labels, c_true, indices, regularize=regularize, lstsq_weights=weights\n",
    "                )\n",
    "                aliasing_err_storage += aliasing_op_norm(M, indices)\n",
    "                M_pinv_norm_storage += norm_M_pinv(M, indices)\n",
    "\n",
    "        data[\"parameter_error\"][\"random\"].append(total_p_err_random / trials)\n",
    "        data[\"aliasing_error\"][\"random\"].append(total_err_random / trials)\n",
    "        data[\"norm_M_pinv\"][\"random\"].append(total_M_pinv_random / trials)\n",
    "        data[\"parameter_error\"][\"leverage\"].append(total_p_err_levg / trials)\n",
    "        data[\"aliasing_error\"][\"leverage\"].append(total_err_levg / trials)\n",
    "        data[\"norm_M_pinv\"][\"leverage\"].append(total_M_pinv_levg / trials)\n",
    "        data[\"parameter_error\"][\"random_leverage\"].append(\n",
    "            total_p_err_rand_levg / trials\n",
    "        )\n",
    "        data[\"aliasing_error\"][\"random_leverage\"].append(total_err_rand_levg / trials)\n",
    "        data[\"norm_M_pinv\"][\"random_leverage\"].append(total_M_pinv_rand_levg / trials)\n",
    "\n",
    "    return x_axis, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86a6eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d86a6eb",
    "outputId": "bbd2d564-124c-486d-c556-cd0500bdb67e"
   },
   "outputs": [],
   "source": [
    "labels = torch.nn.functional.one_hot(\n",
    "    mnist_y,\n",
    "    num_classes=10,\n",
    ").to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "SAMPLE_POINTS = 20_000\n",
    "\n",
    "SAMPLE_POINT_STEP = 1000\n",
    "SAMPLE_POINT_LOG_STEP = 0.1\n",
    "\n",
    "X_AXIS = [int(10 ** (SAMPLE_POINT_LOG_STEP * i)) for i in range(10, int(np.log10(SAMPLE_POINTS) / SAMPLE_POINT_LOG_STEP) + 1)]\n",
    "\n",
    "\n",
    "TRIALS = 20\n",
    "REGULARIZER = 1e-10\n",
    "\n",
    "print(\"Simulating CNN features...\")\n",
    "print(\"-----------------------\")\n",
    "cnn_x_axis, cnn_data = simulation(\n",
    "    X_AXIS,\n",
    "    mnist_cnn_embedding.float(),\n",
    "    labels,\n",
    "    trials=TRIALS,\n",
    "    regularize=REGULARIZER,\n",
    ")\n",
    "print(\"Simulating RFF features...\")\n",
    "print(\"-----------------------\")\n",
    "rff_x_axis, rff_data = simulation(\n",
    "    X_AXIS,\n",
    "    mnist_rff_features.float(),\n",
    "    labels,\n",
    "    trials=TRIALS,\n",
    "    regularize=REGULARIZER,\n",
    ")\n",
    "print(\"Simulating ReLU features...\")\n",
    "print(\"-----------------------\")\n",
    "relu_x_axis, relu_data = simulation(\n",
    "    X_AXIS,\n",
    "    mnist_relu_features.float(),\n",
    "    labels,\n",
    "    trials=TRIALS,\n",
    "    regularize=REGULARIZER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedfd4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abedfd4f",
    "outputId": "55d111f7-9dbf-4099-cd72-c952a4c3a10e"
   },
   "outputs": [],
   "source": [
    "# Plot results in 4 by 3 grid (4 metrics, 3 datasets)\n",
    "metrics = [\"parameter_error\", \"aliasing_error\", \"norm_M_pinv\"]\n",
    "extra_metrics = [\"Leverage Scores Distribution\"]\n",
    "datasets = {\n",
    "    \"CNN Features\": (cnn_x_axis, cnn_data),\n",
    "    \"RFF Features\": (rff_x_axis, rff_data),\n",
    "    \"ReLU Features\": (relu_x_axis, relu_data),\n",
    "}\n",
    "methods = [\"random\", \"leverage\", \"random_leverage\"]\n",
    "method_labels = {\n",
    "    \"random\": \"Random Sampling\",\n",
    "    \"leverage\": \"Leverage Score Sampling\",\n",
    "    \"random_leverage\": \"Randomized Leverage Score Sampling\",\n",
    "}\n",
    "metric_labels = {\n",
    "    \"parameter_error\": \"Relative Parameter Error\",\n",
    "    \"aliasing_error\": \"Aliasing Operator Norm (fro)\",\n",
    "    \"norm_M_pinv\": \"Frobenius Norm of $M_{TM}^+$\",\n",
    "}\n",
    "method_styles = {\n",
    "    \"random\": \"o--\",\n",
    "    \"leverage\": \"s-.\",\n",
    "    \"random_leverage\": \"^-\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    len(metrics) + len(extra_metrics), len(datasets), figsize=(15, 12)\n",
    ")\n",
    "\n",
    "print(cnn_data[\"parameter_error\"][\"random\"])\n",
    "\n",
    "for col, (dataset_name, (x_axis, data)) in enumerate(datasets.items()):\n",
    "    for row, metric in enumerate(metrics):\n",
    "        ax = axes[row, col]\n",
    "        for method in methods:\n",
    "            ax.plot(\n",
    "                x_axis,\n",
    "                [x.cpu().numpy() for x in data[metric][method]],\n",
    "                method_styles[method],\n",
    "                label=method_labels[method],\n",
    "            )\n",
    "        ax.set_title(f\"{dataset_name} - {metric_labels[metric]}\")\n",
    "        ax.set_xlabel(\"Number of Sampled Points\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_ylabel(metric_labels[metric])\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.grid(True)\n",
    "        if row == 0 and col == 0:\n",
    "            ax.legend()\n",
    "\n",
    "    # Plot leverage scores distribution\n",
    "    ax = axes[len(metrics), col]\n",
    "    if dataset_name == \"CNN Features\":\n",
    "        M = mnist_cnn_embedding.float()\n",
    "    elif dataset_name == \"RFF Features\":\n",
    "        M = mnist_rff_features.float()\n",
    "    else:  # ReLU Features\n",
    "        M = mnist_relu_features.float()\n",
    "\n",
    "    leverage_scores = (\n",
    "        (torch.linalg.norm(torch.linalg.qr(M, mode=\"reduced\").Q, dim=1) ** 2)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    ax.plot(np.sort(leverage_scores)[::-1])\n",
    "    ax.set_title(f\"{dataset_name} - Leverage Scores Distribution\")\n",
    "    ax.set_xlabel(\"Index\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"Leverage Score\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da19e2",
   "metadata": {
    "id": "84da19e2"
   },
   "outputs": [],
   "source": [
    "# Plot leverage scores distribution to observe difference from uniform sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2a161",
   "metadata": {
    "id": "46f2a161"
   },
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 images in color with a resolution of 32x32 pixels, divided into 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). This gives us a 60,000 x 32 x 32 x 3 = 60,000 x 3072 data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92378599",
   "metadata": {
    "id": "92378599"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CifarConvNet:\n\tsize mismatch for net.0.mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).\n\tsize mismatch for net.0.std: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m DEVICE = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m network = CifarConvNet()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/cifar_cnn.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m network.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AliasingOperatorExperiments/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2624\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2616\u001b[39m         error_msgs.insert(\n\u001b[32m   2617\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2619\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2620\u001b[39m             ),\n\u001b[32m   2621\u001b[39m         )\n\u001b[32m   2623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2624\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2625\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2626\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2627\u001b[39m         )\n\u001b[32m   2628\u001b[39m     )\n\u001b[32m   2629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for CifarConvNet:\n\tsize mismatch for net.0.mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).\n\tsize mismatch for net.0.std: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from models.cifar_cnn import CifarConvNet\n",
    "\n",
    "\n",
    "trainset = CIFAR10(root=\"./data\", train=True, download=True)\n",
    "testset = CIFAR10(root=\"./data\", train=False, download=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "network = CifarConvNet()\n",
    "network.load_state_dict(torch.load(\"models/cifar_cnn.pth\", map_location=DEVICE))\n",
    "network.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
