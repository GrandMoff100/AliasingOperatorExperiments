{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29ffa709",
      "metadata": {},
      "source": [
        "# Train CNN on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sGvvJMivGEAS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGvvJMivGEAS",
        "outputId": "3aecc570-61ff-4821-8431-f9215076579a"
      },
      "outputs": [],
      "source": [
        "!pip install graphlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72004e9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72004e9a",
        "outputId": "06fe89fa-af1c-4fc5-a0db-f726887f785c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss = 2.3018\n",
            "Epoch 2: train_loss = 2.2998\n",
            "Epoch 3: train_loss = 2.2876\n",
            "Epoch 4: train_loss = 2.1218\n",
            "Epoch 5: train_loss = 1.6122\n",
            "Epoch 6: train_loss = 1.1916\n",
            "Epoch 7: train_loss = 0.9527\n",
            "Epoch 8: train_loss = 0.8096\n",
            "Epoch 9: train_loss = 0.7089\n",
            "Epoch 10: train_loss = 0.6380\n",
            "Epoch 11: train_loss = 0.5828\n",
            "Epoch 12: train_loss = 0.5435\n",
            "Epoch 13: train_loss = 0.5090\n",
            "Epoch 14: train_loss = 0.4863\n",
            "Epoch 15: train_loss = 0.4616\n",
            "Epoch 16: train_loss = 0.4404\n",
            "Epoch 17: train_loss = 0.4237\n",
            "Epoch 18: train_loss = 0.4090\n",
            "Epoch 19: train_loss = 0.3937\n",
            "Epoch 20: train_loss = 0.3797\n",
            "Epoch 21: train_loss = 0.3671\n",
            "Epoch 22: train_loss = 0.3561\n",
            "Epoch 23: train_loss = 0.3477\n",
            "Epoch 24: train_loss = 0.3374\n",
            "Epoch 25: train_loss = 0.3272\n",
            "Epoch 26: train_loss = 0.3192\n",
            "Epoch 27: train_loss = 0.3114\n",
            "Epoch 28: train_loss = 0.3040\n",
            "Epoch 29: train_loss = 0.2976\n",
            "Epoch 30: train_loss = 0.2894\n",
            "Epoch 31: train_loss = 0.2825\n",
            "Epoch 32: train_loss = 0.2762\n",
            "Epoch 33: train_loss = 0.2695\n",
            "Epoch 34: train_loss = 0.2630\n",
            "Epoch 35: train_loss = 0.2581\n",
            "Epoch 36: train_loss = 0.2504\n",
            "Epoch 37: train_loss = 0.2448\n",
            "Epoch 38: train_loss = 0.2392\n",
            "Epoch 39: train_loss = 0.2334\n",
            "Epoch 40: train_loss = 0.2288\n",
            "Epoch 41: train_loss = 0.2230\n",
            "Epoch 42: train_loss = 0.2181\n",
            "Epoch 43: train_loss = 0.2133\n",
            "Epoch 44: train_loss = 0.2080\n",
            "Epoch 45: train_loss = 0.2038\n",
            "Epoch 46: train_loss = 0.1992\n",
            "Epoch 47: train_loss = 0.1947\n",
            "Epoch 48: train_loss = 0.1912\n",
            "Epoch 49: train_loss = 0.1868\n",
            "Epoch 50: train_loss = 0.1834\n",
            "Epoch 51: train_loss = 0.1796\n",
            "Epoch 52: train_loss = 0.1757\n",
            "Epoch 53: train_loss = 0.1713\n",
            "Epoch 54: train_loss = 0.1682\n",
            "Epoch 55: train_loss = 0.1649\n",
            "Epoch 56: train_loss = 0.1616\n",
            "Epoch 57: train_loss = 0.1584\n",
            "Epoch 58: train_loss = 0.1552\n",
            "Epoch 59: train_loss = 0.1533\n",
            "Epoch 60: train_loss = 0.1499\n",
            "Epoch 61: train_loss = 0.1465\n",
            "Epoch 62: train_loss = 0.1442\n",
            "Epoch 63: train_loss = 0.1411\n",
            "Epoch 64: train_loss = 0.1395\n",
            "Epoch 65: train_loss = 0.1372\n",
            "Epoch 66: train_loss = 0.1338\n",
            "Epoch 67: train_loss = 0.1318\n",
            "Epoch 68: train_loss = 0.1300\n",
            "Epoch 69: train_loss = 0.1280\n",
            "Epoch 70: train_loss = 0.1257\n",
            "Epoch 71: train_loss = 0.1236\n",
            "Epoch 72: train_loss = 0.1215\n",
            "Epoch 73: train_loss = 0.1205\n",
            "Epoch 74: train_loss = 0.1180\n",
            "Epoch 75: train_loss = 0.1163\n",
            "Epoch 76: train_loss = 0.1152\n",
            "Epoch 77: train_loss = 0.1136\n",
            "Epoch 78: train_loss = 0.1119\n",
            "Epoch 79: train_loss = 0.1100\n",
            "Epoch 80: train_loss = 0.1091\n",
            "Epoch 81: train_loss = 0.1074\n",
            "Epoch 82: train_loss = 0.1050\n",
            "Epoch 83: train_loss = 0.1038\n",
            "Epoch 84: train_loss = 0.1028\n",
            "Epoch 85: train_loss = 0.1020\n",
            "Epoch 86: train_loss = 0.1003\n",
            "Epoch 87: train_loss = 0.0996\n",
            "Epoch 88: train_loss = 0.0984\n",
            "Epoch 89: train_loss = 0.0970\n",
            "Epoch 90: train_loss = 0.0952\n",
            "Epoch 91: train_loss = 0.0945\n",
            "Epoch 92: train_loss = 0.0929\n",
            "Epoch 93: train_loss = 0.0918\n",
            "Epoch 94: train_loss = 0.0917\n",
            "Epoch 95: train_loss = 0.0909\n",
            "Epoch 96: train_loss = 0.0892\n",
            "Epoch 97: train_loss = 0.0882\n",
            "Epoch 98: train_loss = 0.0870\n",
            "Epoch 99: train_loss = 0.0864\n",
            "Epoch 100: train_loss = 0.0863\n",
            "Test accuracy: 0.9725\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import graphlearning as gl\n",
        "\n",
        "# ---- Load MNIST data ----\n",
        "mnist_digits, mnist_labels = gl.datasets.load(\"mnist\")\n",
        "\n",
        "# ---- Convert to PyTorch tensors ----\n",
        "X = torch.tensor(mnist_digits, dtype=torch.float32).reshape(-1, 1, 28, 28) / 255.0\n",
        "y = torch.tensor(mnist_labels, dtype=torch.long)\n",
        "\n",
        "## Randomly shuffle\n",
        "indices = torch.randperm(X.shape[0])\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "\n",
        "# ---- Split into train/test ----\n",
        "train_X, test_X = X[:60000], X[60000:]\n",
        "train_y, test_y = y[:60000], y[60000:]\n",
        "\n",
        "train_ds = TensorDataset(train_X, train_y)\n",
        "test_ds = TensorDataset(test_X, test_y)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=256)\n",
        "\n",
        "# ---- Define CNN model ----\n",
        "from models.mnist_cnn import ConvNet\n",
        "\n",
        "# ---- Initialize model, loss, optimizer ----\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model if available\n",
        "from pathlib import Path\n",
        "model_path = Path(\"models/mnist_cnn.pth\")\n",
        "if model_path.exists():\n",
        "    model = ConvNet().to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(\"Loaded pre-trained model.\")\n",
        "else:\n",
        "    model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "# ---- Training loop ----\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: train_loss = {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ---- Evaluation ----\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        preds = model(xb)\n",
        "        correct += (preds.argmax(1) == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "print(f\"Test accuracy: {correct / total:.4f}\")\n",
        "\n",
        "# ---- Save model ----\n",
        "torch.save(model.state_dict(), \"models/mnist_cnn.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
